from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import requests
from bs4 import BeautifulSoup

def get_wikipedia_url_selenium(query: str):
    options = Options()
    # options.add_argument("--headless")  # Báº­t láº¡i náº¿u muá»‘n cháº¡y ná»n
    driver = webdriver.Chrome(options=options)

    try:
        driver.get(f"https://www.google.com/search?q={query}+site:vi.wikipedia.org")
        print("[â³] Chá» pháº§n tá»­ div.yuRUbf a xuáº¥t hiá»‡n...")

        WebDriverWait(driver, 10).until(
            EC.presence_of_all_elements_located((By.CSS_SELECTOR, "a"))
        )

        result_links = driver.find_elements(By.CSS_SELECTOR, "div.yuRUbf a")
        print(f"[ğŸ”] Link trong div.yuRUbf: {len(result_links)}")

        # Náº¿u khÃ´ng cÃ³ káº¿t quáº£ trong div.yuRUbf, fallback sang toÃ n bá»™ <a>
        if not result_links:
            result_links = driver.find_elements(By.CSS_SELECTOR, "a")
            print(f"[ğŸ§ª] Fallback â€“ Tá»•ng sá»‘ <a>: {len(result_links)}")

        for link in result_links:
            href = link.get_attribute("href")
            print("â†’", href)
            if href and "vi.wikipedia.org/wiki/" in href:
                print("âœ… Wikipedia URL tÃ¬m tháº¥y!")
                return href
    except Exception as e:
        print("âŒ Lá»—i khi crawl:", e)
    finally:
        driver.quit()

    return None

def get_content_from_wiki(href):
    if not href:
        print("âŒ KhÃ´ng cÃ³ URL há»£p lá»‡ Ä‘á»ƒ láº¥y ná»™i dung.")
        return None

    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        res = requests.get(href, headers=headers)
        if res.status_code != 200:
            print(f"âŒ KhÃ´ng truy cáº­p Ä‘Æ°á»£c URL: {href}")
            return None

        soup = BeautifulSoup(res.text, "html.parser")
        paragraphs = soup.select("p")
        content = "\n".join(
            p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)
        )
        return content
    except Exception as e:
        print(f"âŒ Lá»—i khi láº¥y ná»™i dung tá»« Wikipedia: {e}")
        return None

if __name__ == "__main__":
    query = "NhÃ  thá» Lá»›n HÃ  Ná»™i"
    print(f"\nğŸ” TÃ¬m Wikipedia vá»›i Selenium cho: {query}")
    url = get_wikipedia_url_selenium(query)
    if url:
        print(f"\nğŸ”— Wikipedia URL: {url}")
        content = get_content_from_wiki(url)
        if content:
            print(f"\nğŸ“„ Ná»™i dung trÃ­ch xuáº¥t (500 kÃ½ tá»± Ä‘áº§u):\n{content[:500]}")
        else:
            print("âŒ KhÃ´ng trÃ­ch Ä‘Æ°á»£c ná»™i dung.")
    else:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y URL Wikipedia.")
