import requests
from bs4 import BeautifulSoup
from urllib.parse import quote

def extract_wiki_content_by_title(title: str) -> str | None:
    """Truy cáº­p trá»±c tiáº¿p vÃ  trÃ­ch xuáº¥t ná»™i dung tá»« trang Wikipedia tiáº¿ng Viá»‡t."""
    # Encode tiÃªu Ä‘á» Ä‘á»ƒ Ä‘áº£m báº£o URL há»£p lá»‡
    encoded_title = quote(title.replace(" ", "_"))
    url = f"https://vi.wikipedia.org/wiki/{encoded_title}"

    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(url, headers=headers)

    if res.status_code != 200:
        print(f"âŒ KhÃ´ng truy cáº­p Ä‘Æ°á»£c URL: {url}")
        return None

    soup = BeautifulSoup(res.text, "html.parser")
    paragraphs = soup.select("p")
    content = "\n".join(
        p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)
    )
    return content

if __name__ == "__main__":
    query = "NhÃ _thá»_Lá»›n_HÃ _Ná»™i"
    print(f"ğŸ“˜ Äang truy xuáº¥t Wikipedia cho: {query}")
    content = extract_wiki_content_by_title(query)

    if content:
        print(f"ğŸ“„ Ná»™i dung trÃ­ch xuáº¥t (500 kÃ½ tá»± Ä‘áº§u):\n{content[:500]}")
    else:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y ná»™i dung.")
