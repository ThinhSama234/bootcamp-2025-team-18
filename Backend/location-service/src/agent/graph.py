from abc import ABC, abstractmethod
from typing import Annotated, Dict, Any
from typing_extensions import TypedDict

from langgraph.graph.message import add_messages
from langgraph.graph import StateGraph, END
from langchain_core.runnables import RunnableLambda
from summarization import summarization
#import spacy
from extract_metadata import fetch_from_mongodb
import sys
import argparse
import os
from vector_database import ingest_data_to_vector_db
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../data-service")))
print(sys.path)
from vector_store.vectordb import VectorDB
from vector_store.version_manager import get_version_timestamp
#nlp = spacy.load("vi_core_news_lg")
class State(TypedDict):
    messages: Annotated[list, add_messages]
    summary:str
    entities: dict
    location_details: list
    response: str

def summarize(state: State) -> State:
    print("ğŸ“ Using Gemini to summarize messages...")
    messages = state.get("messages", [])
    result = summarization(messages)
    state["summary"] = result["summary"]
    state["entities"] = result["entities"]
    print("Entities:", state["entities"])
    return state

def search_vector_db(state: State) -> State:
    print("ğŸ” Searching with summary:", state["summary"])
    manager = VectorDB()
    global faiss_name    

    try:
        results = manager.search(
            faiss_name=faiss_name,
            query=state['summary'],
            top_k=5,
            threshold=0.7  # NgÆ°á»¡ng similarity
        )
        # trong search tráº£ vá» id cá»§a document trong mongodb
        location_details = []
        id_strs = []
        for result in results:
            id_strs.append(result["mongo_id"])
        docs = fetch_from_mongodb(id_strs, URL= "vietnamtourism_URL", collection="vietnamtourism_db", document="vietnamtourism_db")
        for doc, result in zip(docs, results):
            print(f"\nğŸ” Score: {result['score']:.4f}")
            print(result["content"])            
            #metadata = result["metadata"]
            #name = metadata.get("name", "")  # Chá»‰ láº¥y name tá»« metadata
            #category = metadata.get("category", "").lower()
            #address = metadata.get("address", "")
            
            data = doc.get('data', {})
            name = data.get('name', '')
            address = data.get('address', '')
            category = data.get('category', '').lower()
            description = data.get('discription', '')
            location_details.append({
                "name": name,
                "category": category,
                "address": address,
                "score": result["score"],
                "description": description,
            })
        #state["result"] = locations if locations else ["PhÃº Quá»‘c", "ÄÃ  Láº¡t", "VÅ©ng TÃ u"]
        state["location_details"] = location_details
    except Exception as e:
        print(f"Search error: {str(e)}")
        state["location_details"] = []

    return state

def format_output(state: State) -> State:
    print("ğŸ–¼ï¸ Formatting response...")
    
    entities = state["entities"]
    locations = entities.get("locations", [])
    features = entities.get("features", [])
    activities = entities.get("activities", [])
    
    reasons = []
    if locations:
        reasons.append(f"Vá»‹ trÃ­: {', '.join(locations)}")
    if features:
        reasons.append(f"Äáº·c Ä‘iá»ƒm: {', '.join(features)}")
    if activities:
        reasons.append(f"Hoáº¡t Ä‘á»™ng: {', '.join(activities)}")
    reason_text = "Dá»±a trÃªn yÃªu cáº§u: " + "; ".join(reasons) + "."

    location_details = state.get("location_details", [])
    if not location_details:
        suggestion_text = "KhÃ´ng tÃ¬m tháº¥y Ä‘á»‹a Ä‘iá»ƒm phÃ¹ há»£p vá»›i yÃªu cáº§u cá»§a báº¡n."
    else:
        suggestion_text = "Danh sÃ¡ch Ä‘á»‹a Ä‘iá»ƒm gá»£i Ã½:\n"
        for i, detail in enumerate(location_details, 1):
            suggestion_text += (
                f"{i}. {detail['name']} ({detail['description'].capitalize()})\n"
                f"   - Äá»‹a chá»‰: {detail['address']}\n"
                f"   - Äá»™ phÃ¹ há»£p: {detail['score']:.4f}\n"
            )

    state["response"] = (
        f"{reason_text}\n\n"
        f"{suggestion_text}\n"
        f"TÃ³m táº¯t yÃªu cáº§u: {state['summary']}"
    )
    return state

parser = argparse.ArgumentParser(description="Run graph.py with a specific faiss_name")
parser.add_argument("--faiss_name", type=str, help="FAISS name to use for the vector database", default=None)
args = parser.parse_args()

if args.faiss_name:
    faiss_name = args.faiss_name
    print(f"Using provided faiss_name: {faiss_name}")
else:
    try:
        with open("faiss_name.txt", "r") as f:
            faiss_name = f.read().strip()
        print(f"Using existing vector database with faiss_name: {faiss_name}")
    except FileNotFoundError:
        print("No existing vector database found. Creating a new one...")
        faiss_name = ingest_data_to_vector_db()

builder = StateGraph(State)
builder.add_node("Summarize", RunnableLambda(summarize))
builder.add_node("Search", RunnableLambda(search_vector_db))
builder.add_node("Format", RunnableLambda(format_output))

builder.add_edge("Summarize", "Search")
builder.add_edge("Search", "Format")
builder.add_edge("Format", END)

builder.set_entry_point("Summarize")

graph = builder.compile()

messages = [
    "Tuá»‘n Ä‘i Ä‘áº¿n má»™t nÆ¡i nÃ o Ä‘Ã³ á»Ÿ HÃ  Ná»™i.",
    "TÃ´i nghÄ© chÃºng ta nÃªn Ä‘i Ä‘áº¿n má»™t nÆ¡i cá»• kÃ­nh.",
    "tÃ´i nghÄ© nÃªn Ä‘áº¿n khu du lá»‹ch",
    #"NÆ¡i nÃ o Ä‘Ã³ á»Ÿ xÃ£ NgÃ£ NÄƒm cÅ©ng hay Ä‘áº¥y!"
    #"VÆ°á»n cÃ² TÃ¢n Long á»Ÿ SÃ³c TrÄƒng thÃ¬ sao nhá»‰?",
    #"Tuyá»‡t vá»i, nghe nÃ³i áº©m thá»±c á»Ÿ Ä‘áº¥y ráº¥t ngon!",
    #"á» Ä‘Ã³ cÃ³ nhÃ  hÃ ng nÃ o ná»•i tiáº¿ng vÃ  Ä‘á»“ Äƒn ráº» khÃ´ng nhá»‰?"
]

final_state = graph.invoke({"messages": messages})
print("\n Final chatbot output:\n", final_state["response"])